# Hive server2的使用

##一.hiveserver2服务配置

### 1.启动 hiveserver2 服务

进入到hive的bin目录下

```
nohup hiveserver2 1>/dev/null 2>/dev/null &
```

### 2.**启动 beeline 客户端去连接**

（1）用户密码是使用连接mysql的那个账号密码，需要在hive-site.xml里设置用户名跟密码，如下所示：

```
<property>  
        <name>javax.jdo.option.ConnectionUserName</name>  
        <value>root</value>  
        <description>ername to use against metastoredatabase</description>  
</property>  
<property>  
        <name>javax.jdo.option.ConnectionPassword</name>  
        <value>123456</value>  
        <description>password to use against metastoredatabase</description>  
</property> 
```

（2）连接hive

```shell
[root@data-1 apache-hive-2.3.3]# ./bin/beeline 
beeline> !connect jdbc:hive2://192.168.197.218:10000
Connecting to jdbc:hive2://192.168.197.218:10000
Enter username for jdbc:hive2://192.168.197.218:10000: root
Enter password for jdbc:hive2://192.168.197.218:10000: *************
19/11/29 09:54:05 [main]: WARN jdbc.HiveConnection: Failed to connect to 192.168.197.218:10000
Error: Could not open client transport with JDBC Uri: jdbc:hive2://192.168.197.218:10000: Failed to open new session: java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: root is not allowed to impersonate root (state=08S01,code=0)
beeline> 
```

先执行 beeline

然后按图所示输入：!connect jdbc:hive2://192.168.197.218:10000

按回车，然后输入用户名，这个 用户名也是 hadoop 集群的用户名，需要对hdfs配置权限，否则报错。

### 3.解决连接报错问题

（1）beeline连接hiveserver2报错

```
Error: Could not open client transport with JDBC Uri: jdbc:hive2://192.168.197.218:10000: Failed to open new session: java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: root is not allowed to impersonate root (state=08S01,code=0)
```

**解决方式：**

在hadoop的配置文件core-site.xml增加如下配置，重启hdfs，其中“xxx”是连接beeline的用户，将“xxx”替换成自己的用户名即可，这里用root

```
<property>
    <name>hadoop.proxyuser.root.hosts</name>
    <value>*</value>
</property>
<property>
    <name>hadoop.proxyuser.root.groups</name>
    <value>*</value>
</property>
```

“*”表示可通过超级代理“xxx”操作hadoop的用户、用户组和主机 

hadoop的所有节点新加上面的属性，然后重启启动hadoop集群

```
./stop-all.sh
./start-all.sh
```

**再次连接报错**

```
beeline> !connect jdbc:hive2://192.168.197.218:10000
Connecting to jdbc:hive2://192.168.197.218:10000
Enter username for jdbc:hive2://192.168.197.218:10000: root
Enter password for jdbc:hive2://192.168.197.218:10000: *************
19/11/29 10:09:10 [main]: WARN jdbc.HiveConnection: Failed to connect to 192.168.197.218:10000
Error: Could not open client transport with JDBC Uri: jdbc:hive2://192.168.197.218:10000: Failed to open new session: java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create directory /tmp/hive/root/3e882d3a-1179-4086-b642-1a37349e3c8e. Name node is in safe mode.
```

关键信息`Name node is in safe mode.`

**解决方法：**

让hadoop退出安全模式Name node is in safe mode

`hadoop` 处于安全模式，所以需要退出安全模式，一般以如下方法可以解决： 

```
hadoop dfsadmin -safemode leave
```

实在不行还可以用如下方式： 

```
hdfs dfsadmin -safemode leave
```

### 4.连接的正确姿势

```
[root@data-1 apache-hive-2.3.3]# ./bin/beeline 
beeline> !connect jdbc:hive2://192.168.197.218:10000
Connecting to jdbc:hive2://192.168.197.218:10000
Enter username for jdbc:hive2://192.168.197.218:10000: root
Enter password for jdbc:hive2://192.168.197.218:10000: *************
Connected to: Apache Hive (version 2.3.3)
Driver: Hive JDBC (version 2.3.3)
Transaction isolation: TRANSACTION_REPEATABLE_READ
jdbc:hive2://192.168.197.218:10000> 
jdbc:hive2://192.168.197.218:10000> show databases;
+----------------+
| database_name  |
+----------------+
| db             |
| default        |
+----------------+
```

### 5.扩展

**扩展1** ：生产中除了使用hiveserver2+beeline方式操作hive外，有的采用 thriftserver+beeline方式操作hive，thriftserver 是hiveserver的别称。HiveServer和HiveServer2都是基于Thrift的，但是HiveServer不能处理多于一个客户端的并发请求，这是由于HiveServer使用的Thrift接口所导致的限制，不能通过修改HiveServer的代码修正。因此在Hive-0.11.0版本中重写了HiveServer代码得到了HiveServer2，进而解决了该问题。



**扩展2**：thrift简介：Thrift是一个跨语言的服务部署框架，最初由Facebook于2007年开发，2008年进入Apache开源项目。Thrift通过IDL（Interface Definition Language，接口定义语言）来定义RPC（Remote Procedure Call，远程过程调用）的接口和数据类型，然后通过thrift编译器生成不同语言的代码（目前支持C++,Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, Smalltalk和OCaml），并由生成的代码负责RPC协议层和传输层的实现。即Thrift搭建的服务能够实现多语言访问，thrift底层数据交互协议走的是RPC协议。

## 二.图形化客户端连接hive

### 1.下载DBeaver Enterprise

http://www.pc0359.cn/downinfo/132447.html

`或者到939598604的微云下载、路径在/软件/DBeaverEnterprsejhb.rar`

其中压缩包中有相关的破解方式

### 2.DBeaver 连接hive

首先新建一个连接，选择Apache Hive，点击下一步。 

![](https://gitee.com/chenjinhua_939598604/resources/raw/img/static/创建连接.png)

填写连接数据库的用户名、密码、地址、库等相关信息，然后点击编辑连接驱动。 

![](https://gitee.com/chenjinhua_939598604/resources/raw/img/static/创建连接2.png)

点击编辑驱动

![](https://gitee.com/chenjinhua_939598604/resources/raw/img/static/编辑驱动.png)

选择下载/更新

![](https://gitee.com/chenjinhua_939598604/resources/raw/img/static/下载驱动.png) 

测试连接

![](https://gitee.com/chenjinhua_939598604/resources/raw/img/static/测试连接.png)

连接信息

![](https://gitee.com/chenjinhua_939598604/resources/raw/img/static/连接信息.png)

执行sql示例

![](https://gitee.com/chenjinhua_939598604/resources/raw/img/static/执行sql.png)