# Hive在linux的单机版安装

##1.下载hive2.3.3

​    下载地址：http://hive.apache.org/downloads.html，点击download，下载hive2.3.3

##2.安装hive2.3.3

 **2.1.解压**

​    tar -zxvf apache-hive-2.3.3-bin.tar.gz
 **2.2.把解压后的文件移到目录/soft/下**
    mv apache-hive-2.3.3-bin  /soft/apache-hive-2.3.3
**2.3.配置hive环境变量**
    vim /etc/profile

```sehll
HIVE_HOME=/soft/apache-hive-2.3.3
HIVE_CONF_DIR=$HIVE_HOME/conf
PATH=PATH:JAVA_HOME/bin:JRE_HOME/bin:HADOOP_HOME/bin:$HIVE_HOME/bin
export JAVA_HOME JRE_HOME PATH CLASSPATH HADOOP_HOME  HIVE_HOME HIVE_CONF_DIR
```

使配置文件的修改生效
    source /etc/profile

## 3.配置hive

  **3.1 配置hive-site.xml**

复制文件

`cp conf/hive-default.xml.temple conf/hive-site.xml`

```shell
<property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/user/hive/warehouse</value>
</property>
<property>
    <name>hive.exec.scratchdir</name>
    <value>/tmp/hive</value>
</property>
```

所以要在Hadoop集群新建/user/hive/warehouse目录，执行命令

```shell
hadoop fs -mkdir -p  /user/hive/warehouse
hadoop fs -chmod -R 777 /user/hive/warehouse #新建的目录赋予读写权限
hadoop fs -mkdir -p /tmp/hive/#新建/tmp/hive/目录
hadoop fs -chmod -R 777 /tmp/hive #目录赋予读写权限
```

用以下命令检查目录是否创建成功

```
hadoop fs -ls /user/hive
hadoop fs -ls /tmp/hive
```

**3.2 把含有system:java.io.tmpdir的变量删除掉**

```
<value>{system:java.io.tmpdir}</value>
```

**3.3 修改hive-site.xml数据库相关的配置**

```
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>root</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>toor@gzstrong</value>
    </property>
   <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://192.168.197.205:3306/hive</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
    </property>
```

**3.4 将MySQL驱动包上载到Hive的lib目录下**

```
cp /找个驱动/mysql-connector-java-5.1.36.jar $HIVE_HOME/lib/
```

**3.5.新建hive-env.sh文件并进行修改**

vi hive-env.sh

    export HADOOP_HOME=/soft/hadoop-2.7.5
    export HIVE_CONF_DIR=/soft/apache-hive-2.3.3/conf
    export HIVE_AUX_JARS_PATH=/soft/apache-hive-2.3.3/lib

## 4.启动和测试

**4.1.对MySQL数据库初始化**

```
schematool -initSchema -dbType mysql
```

执行成功后，在mysql的hive数据库里已生成metadata数据表

**4.2.启动Hive**

```
./hive
```

**4.3.测试Hive**
成功启动Hive后，会进入hive的命令行模式,下面进行一系列简单测试:

```
hive> show functions;
```

 **4.4.执行新建库、表以及导入数据的测试**
 **4.4.1执行新建数据库的hive命令**

```
hive>create database db; 
hive>use db; 
```

**4.4.2 执行建表sql**

    create table tb(id int, name string) row format delimited fields terminated by ','; 

**4.4.3 造数据**

vim /soft/tb.txt

```
1,lisi
2,zhangsan
3,wangwu
```

**4.4.4 导入数据**

```
hive> load data local inpath '/soft/tb.txt' into table db.tb;
```

**4.4.5.查看是否成功**

```
hive>select * from  db.tb; 
```

**4.4.6.在Hadoop的HDFS页面上查看**

**4.4.7.在MySQL的hive数据库中查看**

查看dbs表，tbls表等

| DB_ID | DESC                  | DB_LOCATION_URI                              | NAME    | OWNER_NAME | OWNER_TYPE |
| ----- | --------------------- | -------------------------------------------- | ------- | ---------- | ---------- |
| 1     | Default Hive database | hdfs://master:9000/user/hive/warehouse       | default | public     | ROLE       |
| 6     |                       | hdfs://master:9000/user/hive/warehouse/db.db | db      | root       | USER       |

**4.4.8 不进入命令行执行查询命令**

```
/soft/apache-hive-2.3.3/bin/hive -e "select * from db.tb"
```

**4.4.9 放入到脚本执行**

在/root/hive.sh新建一个查询脚本

```
select * from db.tb;
```

用hive命令执行脚本

```
/soft/apache-hive-2.3.3/bin/hive -f /root/hive.sh > /root/a.txt
```

查看/root/a.txt

```
1       lisi
2       zhangsan
3       wangwu
```

​			